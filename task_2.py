"""
Задание 2.*
Предложить еще какие-либо варианты (механизмы, подходы, библиотеки, идеи)
для оптимизации памяти и
доказать!!! (наглядно, кодом) их эффективность (на примере профилировщика)
"""
def some_func(d):
 #computations
data = [1,2,..,10000] #large data
for d in data:
 some_func(d)

 import multiprocessing


 def some_func(d):


 # computations
 data = [1, 2,.., 10000]  # large data
 pool = multiprocessing.Pool(processes=number_of_processors)
 r = pool.map(some_func, data)
 pool.close()

 """
 Пользуйтесь многопроцессорной обработкой
Если ваш компьютер выполняет более одного процесса, тогда присмотритесь к многопроцессорной обработке в Python.
Она разрешает распараллеливание в коде. Многопроцессорная обработка весьма затратна, поскольку вам придется 
инициировать новые процессы, обращаться к общей памяти и т.д., поэтому пользуйтесь ей только для большого 
количества разделяемых данных. Для небольших объемов данных многопроцессорная обработка не всегда оправдана.
 """